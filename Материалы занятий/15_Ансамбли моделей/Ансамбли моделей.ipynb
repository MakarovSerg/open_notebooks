{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score \n",
    "from sklearn.metrics import classification_report, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Ансамбли моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ансамблем (Ensemble)**  называется алгоритм, который состоит из ***нескольких*** алгоритмов машинного обучения.\n",
    "\n",
    "Такой подход часто используется для того, чтобы усилить \"положительные качества\" отдельно взятых алгоритмов, которые сами по себе могут работать слабо, а вот в группе - ансамбле давать хороший результат. Объединение нескольких \"слабых\" алгоритмов дает \"сильный\".\n",
    "\n",
    "**Виды ансамблей:**\n",
    "\n",
    "**1. Бэггинг (Bagging)** - объединение ***одинаковых*** моделей, но обученных на ***различных*** случайных выборках из ***одного*** набора данных. \n",
    "\n",
    "Бэггинг направлен на **уменьшение разброса (дисперсии)** в данных и зачастую данный прием предстает в виде алгоритма Случайного леса (Random Forest), где слабые модели - это довольно глубокие случайные деревья.\n",
    "\n",
    "**2. Бустинг (Boosting)** - объединение **одинаковых** моделей, обученных ***последовательно***, причем последующая модель должна исправлять ошибки предыдущей. \n",
    "\n",
    "Бустинг направлен скорее на **уменьшение смещения в данных**, чем на снижение разброса в них. Поэтому в качестве базовых алгоритмов могут браться модели с достаточно высоким смещением, например, неглубокие случайные деревья. Пример алгоритма - Градиентный бустинг (Gradient Boosting) и AdaBoost. Варианты реализации градиентоного бустинга алгоритмов: **XGBoost, LightGBM, CatBoost**\n",
    "\n",
    "**3. Стекинг (Stacking)** - объединение ***разнородных*** \"слабых\" моделей в итоговую \"сильную\" мета-модель или модель второго уровня.\n",
    "\n",
    "<a href='https://habr.com/ru/post/561732/' > Короткая статья про ансамбли </a>\n",
    "\n",
    "<a href='https://ml-handbook.ru/chapters/grad_boost/intro' > Статья про бустинг от ШАД Яндекса </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/MalikaL17/course_materials/blob/main/img/bagging.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Случайных лес (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF (random forest)** — это множество решающих деревьев. В задаче регрессии их ответы ***усредняются***, в задаче классификации принимается решение ***голосованием по большинству***.\n",
    "\n",
    "**Все деревья строятся независимо по следующей схеме:**\n",
    "\n",
    "1. Выбирается подвыборка обучающей выборки размера samplesize (с возвращением, т.е. **бустрап-выборка**) – по ней строится дерево (для каждого дерева — своя подвыборка).\n",
    "\n",
    "2. Для построения каждого расщепления в дереве просматриваем max_features случайных признаков (для каждого нового расщепления — свои случайные признаки).\n",
    "\n",
    "3. Выбираем наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило, до исчерпания выборки (пока в листьях не останутся представители только одного класса), но в современных реализациях есть параметры, которые ограничивают высоту дерева, число объектов в листьях и число объектов в подвыборке, при котором проводится расщепление.\n",
    "\n",
    "\n",
    "**Бутстрап (Bootstrap)** - метод генерации выборок из исходной выборки. Из исходной выборки случайным обрзом \"достается\" N значенией с повторением (т.е. одно и то же зачение может попасть в выборку несколь раз). Такой метод помогает находить различные стат. оценки, когда выборка маленькая, а так же служит для сэмплирования данных в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже пример выбора обучающих данных из исходного набра для случайного леса.\n",
    "\n",
    "<img src=\"https://github.com/MalikaL17/course_materials/blob/main/img/random_forest.PNG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важные параметры:**\n",
    "    \n",
    "- **n_estimators** - количество деревьев в ансамбле\n",
    "- **max_features** - количество случайных признаков в для сэмплинга. По умолчанию - корень из числа признаков\n",
    "- **bootstrap** - сэпмлировать методом бутстрпапа. По умоланию - true, иначе - использует всю выборку для обучения всего дерева\n",
    "- **max_samples** - количество наблюдений для сэмплирования. По умолчанию используем весь поднабор\n",
    "\n",
    "Остальные параметра - такие же, как у дерева: **min_sample_leaf**, **max_depth** ...\n",
    "Не забывайте фиксировать **random_state** для воспроизводимости результатов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  Relatives  \n",
       "0         A/5 21171   7.2500   NaN       0.0          1  \n",
       "1          PC 17599  71.2833   C85       1.0          1  \n",
       "2  STON/O2. 3101282   7.9250   NaN       0.0          0  \n",
       "3            113803  53.1000  C123       0.0          1  \n",
       "4            373450   8.0500   NaN       0.0          0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "df = data.copy()\n",
    "df['Sex'] = df['Sex'].map({'female':1, 'male':0})\n",
    "df['Embarked'] = df['Embarked'].map({'S':0, 'C':1, 'Q':2})\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df['Relatives'] = df['SibSp'] + df['Parch'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дерево решений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения точности при перекрестной проверке: \n",
      "0.7311793489592352\n"
     ]
    }
   ],
   "source": [
    "X = df[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Relatives']]\n",
    "y = df['Survived']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17) #\n",
    "\n",
    "scores = cross_val_score(tree, X, y, cv=kf, scoring='f1')\n",
    "print(\"Значения точности при перекрестной проверке: \\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения точности при перекрестной проверке: \n",
      "0.7531121013523187\n"
     ]
    }
   ],
   "source": [
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=17)\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=kf, scoring='f1') \n",
    "print(\"Значения точности при перекрестной проверке: \\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Градиентный бустинг (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании линейной регрессии делается предположение о нормальности распределения остатков вокруг нуля. Пример остатков для хорошей модели на рисунке ниже.\n",
    "<img src='https://github.com/MalikaL17/course_materials/blob/main/img/boosting_0.PNG?raw=true'>\n",
    "\n",
    "Похожей логки можно придерживаться при обучении других алгоритмов. \n",
    "\n",
    "**Интуиция за алгоритмом градиентного бустинга**: итеративно применять паттерны отклонений и улучшать предсказания. Как только мы достигли момента, когда отклонения не имеют никакого паттерна, мы прекращаем достраивать нашу модель. Общая последовательность действий такая:\n",
    "- Сначала строим простые модели и анализируем ошибки\n",
    "- Определяем точки, которые не вписываются в простую модель\n",
    "- Добавляем модели, которые обрабатывают сложные случаи, которые были выявлены на начальной модели\n",
    "- Собираем все построенные модели, определяя вес каждого предсказателя\n",
    "\n",
    "Иллюстрация итеративного процесса представлена ниже:\n",
    "\n",
    "<img src='https://github.com/MalikaL17/course_materials/blob/main/img/boosting_1.PNG?raw=true'>\n",
    "В итоге, на 50 итерации получаем:\n",
    "<img src='https://github.com/MalikaL17/course_materials/blob/main/img/boosting_2.PNG?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоговое предсказание модели** - взвешенная сумма предсказаний слабых алгоритмов:\n",
    "$$ prediction = \\sum_{i=1}^m C_i\\cdot a_i  $$ \n",
    "$C_i$ - весовые коэффициенты    \n",
    "$a_i$ - предсказания слабых алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Цель любого алгоритма обучения с учителем — определить функцию потерь и минимизировать её. Давайте обратимся к математике градиентного бустинга. Пусть, например, в качестве функции потерь будет среднеквадратичная ошибка (MSE):\n",
    "\n",
    "$$ MSE = \\sum(Y_i - Y_i^p)^{2} $$\n",
    "\n",
    "Мы хотим построить наши предсказания таким образом, чтобы MSE была минимальна. Используя градиентный спуск и обновляя предсказания, основанные на скорости обучения (learning rate), ищем значения, на которых MSE минимальна.\n",
    "\n",
    "Для объяснения метода градиентного бустинга полезно воспользоваться следующей аналогией. Бустинг можно представить как гольфиста, цель которого – загнать мяч в лунку с координатой yball. Положение мяча здесь – ответ композиции a(xball). Гольфист мог бы один раз ударить по мячу, не попасть в лунку и пойти домой, но настырность заставляет его продолжить\n",
    "\n",
    "<img src=\"https://github.com/MalikaL17/course_materials/blob/main/img/gradient_decent.png?raw=true\">\n",
    "\n",
    "По счастью, ему не нужно начинать каждый раз с начальной позиции. Следующий удар гольфиста переводит мяч из текущего положения ak(xball) в положение ak+1(xball). Каждый следующий удар – это та поправка, которую вносит очередной базовый алгоритм в композицию. Если гольфист все делает правильно, то функция потерь будет уменьшаться, то есть мяч постепенно будет приближаться к лунке.\n",
    "\n",
    "Удары при этом делаются не хаотично. Гольфист оценивает текущее положение мяча относительно лунки и следующим ударом старается нивелировать те проблемы, которые он создал себе всеми предыдущими. Подбираясь к лунке, он будет бить всё аккуратнее и, возможно, даже возьмет другую клюшку, но точно не будет лупить так же, как из первоначальной позиции. В итоге комбинация всех ударов рано или поздно перенесет мяч в лунку.\n",
    "\n",
    "Подобно тому, как гольфист постепенно подводит мяч к цели, бустинг с каждым новым базовым алгоритмом всё больше приближает предсказание к истинному значению метки объекта.\n",
    "\n",
    "В нашей задаче мы хотим найти направление, вдоль которого уменьшается функция потерь (MSE). Для этой цели нам нужно найти **антиградиент** функции потерь.\n",
    "Из математики мы помним, что **градиент функции** - это вектор, указывающий на направление скорейшего роста функции. Тогда **антиградиент** - направление скорешего убывания функции. Полученное значение антиградиента используется для обучения следующего алгоритма, вместо обычной ошибки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скорость обучения (learning rate)\n",
    "\n",
    "Обучение композиции с помощью градиентного бустинга может привести к переобучению, если базовые алгоритмы слишком сложные. Например, если сделать решающие деревья слишком глубокими (более 10 уровней), то при обучении бустинга ошибка на обучающей выборке даже при довольно скромном K может приблизиться к нулю, то есть предсказание будет почти идеальным, но на тестовой выборке всё будет плохо.\n",
    "\n",
    "Существует два решения этой проблемы:\n",
    "- Упростить базовую модель, уменьшив глубину дерева (либо примерив какие-либо ещё техники регуляризации)\n",
    "- Ввести параметр, называемый скоростью (темпом) обучения - **learning rate**,  η ∈(0,1], который отвечает за то, чтобы каждый базовый алгоритм вносит относительно небольшой вклад в результат. Фактически **learning rate** представляет собой вес вклада базового алгоритма в итоговое решение\n",
    "\n",
    "В результате, итоговое предсказание алгоритма будет выглядеть следующим образом:\n",
    "\n",
    "$$ prediction = a_1 + \\sum_{i=2}^m \\eta \\cdot C_i\\cdot a_i  $$ \n",
    "\n",
    "$a_1$ - 1-й базовый алгоритм, который предсказывает исходную целевую переменную \n",
    "\n",
    "$a_i$ - предсказания i-x базовых алгоритмов, предсказывающих ошибку на i-1 шаге (2-й алгоритм и последующие)  \n",
    "$C_i$ - весовые коэффициенты алгоритмов   \n",
    "$\\eta$ - скорость обучения  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть несколько реализаций градиентного бустинга:\n",
    "\n",
    "1. Градиентный бустинг из sklearn\n",
    "2. XGBoost\n",
    "3. LightGBM\n",
    "4. CatBoost\n",
    "...\n",
    "\n",
    "В рамках данного занятия рассмотрим градиентный бустинг из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_boston = load_boston()\n",
    "df = pd.DataFrame(data_boston.data, columns=data_boston.feature_names)\n",
    "df['Price'] = data_boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дерево решений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения точности при перекрестной проверке: \n",
      "-2.983275092215104\n"
     ]
    }
   ],
   "source": [
    "columns_to_use = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "X = df[columns_to_use]\n",
    "y = df['Price']\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(tree, X, y, cv=kf, scoring='neg_mean_absolute_error') \n",
    "print(\"Значения точности при перекрестной проверке: \\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения точности при перекрестной проверке: \n",
      "-2.209312017084061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "columns_to_use = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "X = df[columns_to_use]\n",
    "y = df['Price']\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf, X, y, cv=kf, scoring='neg_mean_absolute_error') \n",
    "print(\"Значения точности при перекрестной проверке: \\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиентный бустинг** \n",
    "\n",
    "Параметр **loss** (функция потерь) необходимо указывать в объекте моделе бустинга, т.к. именно по указанной функции потерь будет обучаться бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения точности при перекрестной проверке: \n",
      "-2.195887148126577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr =  GradientBoostingRegressor(loss='lat', random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf, X, y, cv=kf, scoring='neg_mean_absolute_error') \n",
    "print(\"Значения точности при перекрестной проверке: \\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что при параметрах по умолчанию градиентный бустинг выдает наименьшую ошибку."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
